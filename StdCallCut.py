
from common import *
from sklearn.feature_extraction import DictVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import normalize
import numpy as np
import pickle
import sys

main_path = os.path.join(root_path, "train")

model_dir = os.path.join(main_path, model_dir)
dll_feat_dir = os.path.join(main_path, dll_feat_dir)
dll_matrix_path = os.path.join(main_path, dll_matrix_path)
opcode_feat_dir = os.path.join(main_path, opcode_feat_dir)
opcode_matrix_path = os.path.join(main_path, opcode_matrix_path)
sectionhist_feat_dir = os.path.join(main_path, sectionhist_feat_dir)
section_matrix_path = os.path.join(main_path, section_matrix_path)
stdcall_feat_dir = os.path.join(main_path, stdcall_feat_dir)
stdcall_matrix_path = os.path.join(main_path, stdcall_matrix_path)
byte_feat_dir = os.path.join(main_path, byte_feat_dir)
byte1g_matrix_path = os.path.join(main_path, byte1g_matrix_path)
byte1f_matrix_path = os.path.join(main_path, byte1f_matrix_path)
byte2g_matrix_path = os.path.join(main_path, byte2g_matrix_path)
byte4g_matrix_path = os.path.join(main_path, byte4g_matrix_path)
byte_image_feat_dir = os.path.join(main_path, byte_image_feat_dir)
byte_image_matrix_path = os.path.join(main_path, byte_image_matrix_path)

dict = {}

feat_files = [os.path.join(stdcall_feat_dir, file) for file in os.listdir(stdcall_feat_dir) if os.path.isfile(os.path.join(stdcall_feat_dir, file))]
res = [pickle.load(open(file, "rb")) for file in feat_files]

# Count functions based on how many times they appear in different files
for file in feat_files:
    d = pickle.load(open(file, "rb"))
    for key, value in d.items():
        dict[key] = dict.get(key, 0) + 1

# Delete functions that does not appear in more than 5 files        
todelete = []
for key, value in dict.items():
    if value <= 10:
        todelete.append(key)
        
for i in todelete:
    del dict[i]

pickle.dump(dict, open(stdcall_cut_path, "wb"))