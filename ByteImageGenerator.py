
from skimage import data
from scipy import ndimage as ndi
from sortedcontainers import SortedDict
from skimage import transform
from skimage.filters import gabor_kernel
from common import *
from Grebber import chunks
from multiprocessing import Process
import pickle
import numpy as np
from progressbar import Percentage, Bar, ProgressBar, ETA
import sys


def gray2rgb(img):
    w, h = img.shape
    ret = np.empty((w, h, 3), dtype=np.uint8)
    ret[:, :, 0] = img
    ret[:, :, 1] = ret[:, :, 2] = ret[:, :, 0]
    return ret
    
    
def calcKernels():
    kernels = []
    for theta in range(8):
        theta = theta / 4. * np.pi
        for sigma in (1, 3):
            for frequency in (0.05, 0.25):
                kernel = np.real(gabor_kernel(frequency, theta=theta,
                                              sigma_x=sigma, sigma_y=sigma))
                kernels.append(kernel)
    return kernels
                
                
def compute_feats(image, kernels):
    feats = np.zeros((len(kernels)*2, 1), dtype=np.double)
    for k, kernel in enumerate(kernels):
        filtered = ndi.convolve(image, kernel, mode='wrap')
        feats[2*k] = filtered.mean()
        feats[2*k+1] = filtered.var()
    return feats
                
    
def calcGistFeatures(bytes, kernels):
    # Create byte array
    byteImage = []
    for row in bytes:
        rowList = row.split(' ')[1:]
        if len(rowList) != 16:
            continue
        for item in rowList:
            if item == "??":
                byteImage.append(257)
            else:
                byteImage.append(int(item, 16))
    
    # Reshape to image
    totalSizeKB = len(byteImage)/1024
    byteImage = np.array(byteImage)
    widthMap = SortedDict({0:64, 30:128, 60:256, 100:384, 200:512, 500:768, 1000:1024})
    width = widthMap.values()[widthMap.bisect_right(totalSizeKB)-1]
    height = int(len(byteImage)/width)
    byteImage = byteImage[:width*height]
    byteImage = byteImage.reshape(width, -1)
    byteImage = transform.resize(byteImage, (64, 64), preserve_range=True)
    # print(byteImage.shape)
    feat = compute_feats(byteImage, kernels)
    # print(feat.shape)
    
    # Downsample image to 64x64
    # byteImage = block_reduce(byteImage, block_size=(int(byteImage.shape[0]/64), int(byteImage.shape[1]/64)), func=np.mean)
    # print(byteImage.shape)
    return feat
    
    
def worker(chunk, output_dir):
    widgets = ['Worker {}: '.format(chunk[0]), ' ', Percentage(), ' ', Bar(), ' ', ETA()]
    pbar = ProgressBar(widgets=widgets, maxval=len(chunk[1])).start()
    kernels = calcKernels()
    for idx, item in enumerate(chunk[1]):
        fn = item.split(os.sep)[-1].split(".")[0]
        
        # Save data
        data = calcGistFeatures(r.readBytes(item), kernels)
        pickle.dump(data, open(os.path.join(output_dir, fn), "wb"))
        
        # Update progressbar
        pbar.update(idx+1)
    pbar.finish()
    
if __name__ == "__main__":
    print("Byte image features extraction started!")
    
    
    if sys.argv[1] == "train":
        main_path = os.path.join(root_path, "train")
        split_data = chunks(train_bytes, numWorkers)
    else:
        main_path = os.path.join(root_path, "test")
        split_data = chunks(test_bytes, numWorkers)
    
    output_dir = os.path.join(main_path, byte_image_feat_dir)
    
    clearPath(output_dir)
        
    jobs = []        
    for item in enumerate(split_data):
        p = Process(target=worker, args=(item, output_dir))
        jobs.append(p)
        p.start()
        
    for j in jobs:
        j.join()
        
    print("Byte image features extraction completed!")