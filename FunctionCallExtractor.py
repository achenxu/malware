
from Grebber import chunks
import Reader as r
import os
from common import *
from multiprocessing import Process
import pickle
from progressbar import Percentage, Bar, ProgressBar, ETA
import sys

    
def getFunctionNames(fn):
    text = r.readAsmCode(fn)
    funcDict = {}
    
    for row in text:
        if "PRESS" in row:
            funcName = row[row.index("FUNCTION"):row.index("PRESS")].split(".")[0].split(" ")[-1]
            funcDict[funcName] = funcDict.get(funcName, 0) + 1
    return funcDict
    
    
def worker(chunk, output_dir):
    widgets = ['Worker {}: '.format(chunk[0]), ' ', Percentage(), ' ', Bar(), ' ', ETA()]
    pbar = ProgressBar(widgets=widgets, maxval=len(chunk[1])).start()
    for idx, item in enumerate(chunk[1]):
        # Filenames
        fn = item.split(os.sep)[-1].split(".")[0]
        
        # Extract features
        funcDict = getFunctionNames(item)
        
        # Save features
        pickle.dump(funcDict, open(os.path.join(output_dir, fn), "wb"))
        
        # Update progressbar
        pbar.update(idx+1)
    pbar.finish()
    
if __name__ == "__main__":
    print("FunctionCall Extractor started!")
    
    data_dir = os.path.join(root_path, os.path.join("data", "function"))
    data = [os.path.join(data_dir, file) for file in os.listdir(data_dir) if os.path.isfile(os.path.join(data_dir, file))]
    
    split_data = chunks(data, numWorkers)
    
    # Directory name
    output_dir = os.path.join(root_path, os.path.join("feat", "function"))
     
    clearPath(output_dir)
    
    # Parallel threading
    jobs = []
    for item in enumerate(split_data):
        p = Process(target=worker, args=(item, output_dir))
        jobs.append(p)
        p.start()
        
    for j in jobs:
        j.join()     

    print("FunctionCall Extractor completed!")