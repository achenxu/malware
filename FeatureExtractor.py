# Code that extracts info on file lengths

from Grebber import chunks
from common import *
from multiprocessing import Process
from progressbar import Percentage, Bar, ProgressBar, ETA
from scipy.stats import entropy
from skimage import data
from scipy import ndimage as ndi
from sortedcontainers import SortedDict
from skimage import transform
from skimage.filters import gabor_kernel

import numpy as np
import Reader as r
import os
import sys
import pickle

# Byte image features
def gray2rgb(img):
    w, h = img.shape
    ret = np.empty((w, h, 3), dtype=np.uint8)
    ret[:, :, 0] = img
    ret[:, :, 1] = ret[:, :, 2] = ret[:, :, 0]
    return ret
    
    
def calcKernels():
    kernels = []
    for theta in range(8):
        theta = theta / 4. * np.pi
        for sigma in (1, 3):
            for frequency in (0.05, 0.25):
                kernel = np.real(gabor_kernel(frequency, theta=theta,
                                              sigma_x=sigma, sigma_y=sigma))
                kernels.append(kernel)
    return kernels
                
                
def compute_feats(image, kernels):
    feats = np.zeros((len(kernels)*2, 1), dtype=np.double)
    for k, kernel in enumerate(kernels):
        filtered = ndi.convolve(image, kernel, mode='wrap')
        feats[2*k] = filtered.mean()
        feats[2*k+1] = filtered.var()
    return feats
                
    
def calcGistFeatures(bytes, kernels):
    # Create byte array
    byteImage = []
    for row in bytes:
        rowList = row.split(' ')[1:]
        if len(rowList) != 16:
            continue
        for item in rowList:
            if item == "??":
                byteImage.append(257)
            else:
                byteImage.append(int(item, 16))
    
    # Reshape to image
    totalSizeKB = len(byteImage)/1024
    byteImage = np.array(byteImage)
    widthMap = SortedDict({0:64, 30:128, 60:256, 100:384, 200:512, 500:768, 1000:1024})
    width = widthMap.values()[widthMap.bisect_right(totalSizeKB)-1]
    height = int(len(byteImage)/width)
    byteImage = byteImage[:width*height]
    byteImage = byteImage.reshape(width, -1)
    byteImage = transform.resize(byteImage, (64, 64), preserve_range=True)
    # print(byteImage.shape)
    feat = compute_feats(byteImage, kernels)
    # print(feat.shape)
    
    # Downsample image to 64x64
    # byteImage = block_reduce(byteImage, block_size=(int(byteImage.shape[0]/64), int(byteImage.shape[1]/64)), func=np.mean)
    # print(byteImage.shape)
    return feat
    
# Extracts info on file lengths
def extractLengthFeatures(code, bytes):
    asmLength = len(code)/1024
    byteLength = len(bytes)/1024
    ratio = len(code)/len(bytes)
        
    return [asmLength, byteLength, ratio]
    
# Extracts info from disassembled code
def extractAssemblyFeatures(code):
    opcodeDict = {i:0 for i in opcodeList}
    DLLDict = {}
    sectionDict = {i:0 for i in sectionList}
    callDict = {}
    funcDict = {}
    
    for row in code:
        # Opcode information
        if row.startswith(".text"):
            for item in row.split()[1:]:
                if item in opcodeDict:
                    opcodeDict[item] += 1
                    
        # DLL information
        if row.startswith(".idata") and 'Imports from' in row and '.dll' in row:
            DLLName = row[row.index('from'):row.index('.dll')].strip().split(" ")[-1].lower()
            DLLDict[DLLName] = DLLDict.get(DLLName, 0) + 1
        
        # Section length information
        sectionName = row.split(":")[0].lower()
        if sectionName in sectionDict:
            sectionDict[sectionName] = sectionDict.get(sectionName, 0) + 1    

        if "__stdcall" in row and "(" in row:
            callName = row.split("__stdcall")[1].strip().split("(")[0]
            callDict[callName] = callDict.get(callName, 0) + 1
            
        if "FUNCTION" in row and "PRESS" in row:
            funcName = row[row.index("FUNCTION"):row.index("PRESS")].split(".")[0].split(" ")[-1]
            funcDict[funcName] = funcDict.get(funcName, 0) + 1
        
    return opcodeDict, DLLDict, sectionDict, callDict, funcDict
    
    
def byteEntropy(byteFreq):
    probs = np.array(byteFreq)
    probs = probs/probs.sum()
    ent = entropy(probs)
    return ent
    
    
def findIndex(lst):
    res = 0
    for idx, val in enumerate(lst):
        res += val*(257**idx)
    return res
    
    
def byteSeqToInt(seq):
    bytes = []
    for row in seq:
        for item in row.split(' ')[1:]:
            if item != "??":
                bytes.append(int(item, 16))
            else:
                bytes.append(256)
    return bytes
    
    
def extractByteFeatures(bytes):
    bytes = byteSeqToInt(bytes)
    
    # 1gram
    byte1gram = [0]*257
    for item in bytes:
        byte1gram[item] += 1
        
    # 2gram
    n = 2
    byte2gram = {}
    for i in range(len(bytes)-n+1):
        idx = findIndex(bytes[i:i+n])
        byte2gram[idx] = byte2gram.get(idx, 0) + 1
    
    # 4gram
    n = 4
    byte4gram = {}
    for i in range(len(bytes)-n+1):
        idx = findIndex(bytes[i:i+n])
        byte4gram[idx] = byte4gram.get(idx, 0) + 1
        
    res = {'1g': byte1gram, '1f':byteEntropy(byte1gram), '2g':byte2gram, '4g':byte4gram}
    
    return res
    
# Function to run for each worker
def worker(chunk, output_dir):
    widgets = ['Worker {}: '.format(chunk[0]), ' ', Percentage(), ' ', Bar(), ' ', ETA()]
    pbar = ProgressBar(widgets=widgets, maxval=len(chunk[1])).start()
    kernels = calcKernels()
    for idx, item in enumerate(chunk[1]):
        # Filenames
        fn = item.split(os.sep)[-1].split(".")[0]
        
        # Read asm code
        asm = r.readAsmCode(item)
        bytes = r.readBytes(item.split(".")[0]+".bytes")
        
        # Extract features
        lengthFeat = extractLengthFeatures(asm, bytes)
        opcodeDict, DLLDict, sectionDict, callDict, funcDict = extractAssemblyFeatures(asm)
        gistFeat = calcGistFeatures(bytes, kernels)
        byteFeat = extractByteFeatures(bytes)
        
        feat = {'length':lengthFeat, "opcode":opcodeDict, "DLL":DLLDict, 
        "section":sectionDict, "stdcall":callDict, "function":funcDict, 
        "image":gistFeat, "byte":byteFeat}
        
        # Save features
        pickle.dump(feat, open(os.path.join(output_dir, fn), "wb"))
        
        # Update progressbar
        pbar.update(idx+1)
    pbar.finish()
    
if __name__ == "__main__":
    print("Feature extractor started!")
    
    # Which dataset? Train or test?
    if sys.argv[1] == "train":
        main_path = os.path.join(root_path, "train")
        split_data = chunks(train_asm, numWorkers)
    else:
        main_path = os.path.join(root_path, "test")
        split_data = chunks(test_asm, numWorkers)
    
    # Directory name
    output_dir = os.path.join(main_path, feat_dir)
    
    clearPath(output_dir)
        
    # Multi threading
    jobs = []
    for item in enumerate(split_data):
        p = Process(target=worker, args=(item, output_dir))
        jobs.append(p)
        p.start()
    
    for j in jobs:
        j.join()
        
    print("Feature extractor completed!")
        